%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Arsclassica Article % LaTeX Template
% Version 1.1 (10/6/14)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Lorenzo Pantieri (http://www.lorenzopantieri.net) with extensive modifications by:
% Vel (vel@latextemplates.com)
% Johan Bos (johan.bos@rug.nl)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
10pt, % Main document font size
a4paper, % Paper type, use 'letterpaper' for US Letter paper
oneside, % One page layout (no page indentation)
%twoside, % Two page layout (page indentation for binding and different headers)
headinclude,footinclude, % Extra spacing for the header and footer
%BCOR5mm, % Binding correction
] {book}% {scrartcl}

\input{structure.tex} % Include the structure.tex file which specified the document structure and layout


%----------------------------------------------------------------------------------------
%	HYPHENATION
%----------------------------------------------------------------------------------------
% Specify custom hyphenation points for particular words with dashes where
% hyphenation is allowed, or alternatively, don't put any dashes in a
% word to prevent hyphenation altogether. Expand this list as needed.
\hyphenation{Fortran hy-phen-ation}



%----------------------------------------------------------------------------------------
%	TITLE AND AUTHOR(S)
%----------------------------------------------------------------------------------------

\title{\normalfont\spacedallcaps{title}} % The article title

\author{\spacedlowsmallcaps{author}} % The article author(s) - author affiliations need to be specified in the AUTHOR AFFILIATIONS block

\date{} % An optional date to appear under the author(s)

%----------------------------------------------------------------------------------------

\begin{document}

%----------------------------------------------------------------------------------------
%\lehead{\mbox{\llap{\small\thepage\kern1em\color{halfgray} \vline}\color{halfgray}\hspace{0.5em}\rightmark\hfil}} % The header style

\pagestyle{scrheadings} % Enable the headers specified in this block


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\hypersetup{pageanchor=false}
\begin{titlepage}
\thispagestyle{empty}
\begin{figure}[h!] %  figure placement: here, top, bottom, or page
\includegraphics[width=4in]{ruglogo} 
% \includegraphics[width=4in]{ruglogo-nl}   % Dutch version
\end{figure}

\begin{center}
\vspace{30 mm}
\begingroup \linespread{1,75} \selectfont 
\textsc{\LARGE Language and Dialect identification}\\
	\textsc{\Large How Twitter can be used to create a corpus of a specific (regional) language}\\[1,5cm]
\endgroup

Lennart Albert Schepers\\[2,5cm]

\end{center}
\vfill
\textbf{Bachelor thesis}\\  %\textbf{Master thesis}\\
Informatiekunde\\  %Information Science\\
Lennart Albert Schepers\\
S2922916\\
\today
\end{titlepage}
\hypersetup{pageanchor=true}


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\pagenumbering{roman}
\chapter*{Abstract}
\markboth{Abstract}{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

Language identification, especially when nuanced down to regional language identification, is a rather new area in the field of machine learning. This work focusses on the generation of a corpus of messages submitted to Twitter written in both Frisian and the neighboring regional language of Gronings. With the help of queries that consist of multiple, carefully selected keywords, an annotated corpus of Gronings, Fries and Dutch was compiled. On this corpus, two machine learning models are trained: a Naive Bayes model and a support vector classification model. Both models achieved high accuracy during testing. For the task of distinguishing Frisian and Gronings from Dutch, the Naive Bayes model returned an average F-measure of 0.990535 and the SVC model achieved an average F-measure of 0.994913.
%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS & LISTS OF FIGURES AND TABLES
%----------------------------------------------------------------------------------------
\clearpage
\setcounter{tocdepth}{3} % Set the depth of the table of contents to show sections and subsections only
\tableofcontents % Print the table of contents

%\listoffigures % Print the list of figures (optional, only if you have many figures)

%\listoftables % Print the list of tables (optional, only if you have many tables)

%\lstlistoflistings




%----------------------------------------------------------------------------------------
%	Preface
%----------------------------------------------------------------------------------------

\chapter*{Preface}
\markboth{Preface}{Preface}
\addcontentsline{toc}{chapter}{Preface}

Special thanks to Martijn Bartelds for supervising and guiding the process of writing this thesis. The isolation due to the Corona epidemic made concentrating on tasks like these much harder, but you provided thorough and honest feedback which helped me a lot.





%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\chapter{Introduction}
\pagenumbering{arabic}

Textual communication is becoming increasingly important. In the digital age people are expressing themselves via relatively short messages on various social networks \citep{Hughes}. The creation of such corpora resulting from Twitter is interesting because they do not yet exist. 
Currently Twitter labels tweets in only 34 languages and no dialects \footnote{https://developer.twitter.com/en/docs/twitter-for-websites/twitter-for-websites-supported-languages/overview}. The process of automatically assigning labels to dialects could be very interesting from a linguistic point of view because this new data could be used to get more insight on phenomena that are still being researched. Examples of this could be that creating a corpus of one or more (regional) languages through the plethora of short messages that Twitter provides could give unique insights on how these specific dialects are used in the modern digital age, or the code switching that might occur in speakers of a certain dialect \citep{Biadsy}. There doesn't yet exist such a corpus created from Twitter messages that combines Frisian and Gronings, which is why this work will contribute to the scientific status quo.

\section{The Gronings dialect}
Gronings is a collection of multiple varieties of regional languages spoken mainly in the northern Dutch province of Groningen. The usage of Groningen is not just confined to the province of Groningen, as some disagreement exists whether or not the dialect spoken in the northern part of neighboring province Drenthe (referred to as 'Noordervelds' can be allocated to Gronings because of similar phonological characteristics; such as the 'ou' and 'ei' sounds which are typical for a Gronings dialect, rather than 'oe' and 'ie' which would be usual for the 'Drents' dialect \citep{streektalen}. Then there is the border with the province of Friesland, where the Gronings variety of 'Westerkwartiers' crosses territory. These two examples are main reasons why the Gronings dialect family is not just confined to the border of its province.

Gronings can be subdivided into seven main dialects: 'Stadjeders', Kollumpompers', 'Westerkwartiers', 'Hogelandsters', 'Oldambsters', 'Veenkoloniaals' and 'Westerwolds' (citation needed). 

These dialects are not used as widely as they once were; research conducted in 2018 reported that around 65 percent of Groningen civilians can speak and write in the Gronings dialect \citep{Sprekers}. while this means that Gronings is still one of the bigger dialects in the Netherlands, it also shows that usage has been in a decline. Gronings used to be the most prominent language of the province in the beginning of the 1900's, rather than being used by just 65 percent of civilians like it is now \citep{Sprekers}. Younger generations in Groningen can often times speak the dialect to an extent, but will have the tendency to morph the dialect into a hybrid of regular Dutch and Gronings, as Dutch is the national norm for communication \citep{streektalen}. Due to globalization, dialects in general are under pressure, because digital communication does not have the municipal constraints that dialects are built on \citep{globalization}. This has lead to parents teaching their children Dutch as their first language in favour of  Gronings. Digital media make regional languages increasingly superfluous, which can be seen in the declining usage of these dialects.\citep{globalization} 

This increased importance of Dutch over the last decades in Groningen has influences a hybrid of Dutch and Gronings \citep{globalization}. This so called 'Gronings Dutch' is a mixture of Dutch with syntactical or lexical characteristics of Gronings.  Examples would be the sentence 'Mag ik een puutje erbij?'. The proper Dutch sentence would be: 'Mag ik een tasje erbij?'. The Dutch Gronings sentence is identical except for the Gronings word: 'puutje'. Another example would be the Dutch Gronings sentence 'je doet me daar geen knup om toe'. In proper Dutch this sentence would be something like 'Je doet er geen knoop om'. Here more differences are visible; the Dutch Gronings sentence contains the Gronings word 'knup' and the Gronings syntactical structure of the place of the words: 'me' and 'ergens om toe'. Other than that the two sentences are the same.

\section{The Frisian language}
Like Gronings, the Frisian language is a collection of strongly related languages. The Frisian language belongs to the west Germanic branch of the Germanic language family and is closely related to English \citep{streektalen}. These languages are spoken in the Dutch province of Friesland (also slightly crossing the border into Groningen in the municipality of 'Westerkwartier') and in the German states of 'Nedersaksen' and 'Sleeswijk-Holstein' \citep{streektalen}. The variety of Frisian that is spoken in the Dutch province of Friesland is scientifically named 'Westerlauwers Fries'. Since this is the variety of Frisian that this research focusses on, will be just referred to as the regular Dutch designation of 'Fries' from now on. 

Fries is the official second language of the Netherlands since 1956 and an official language in the province of Friesland, next to Dutch since 2013 \footnote{https://wetten.overheid.nl/BWBR0034047/2014-01-01}. As an official language, a standard has been developed that is based on two of six main dialects of Fries: 'Kleifries' and 'Woudfries' \citep{streektalen}. This standard (which is scientifically named Westerlauwers Fries) is used for educational and local governmental purposes. Fries is a mandatory subject in primary school in Friesland, which helps maintain the knowledge of the language among residents of Friesland \footnote{https://www.rijksoverheid.nl/onderwerpen/basisonderwijs/vraag-en-antwoord/welke-vakken-krijgt-een-kind-op-de-basisschool}. Fries is also an optional subject in high school. Some universities, like the university of Groningen, provide the option of an educational master to become a teacher of Fries \footnote{https://www.rug.nl/masters/language-and-culture-education-frisian-language-and-culture/}. \\

As mentioned before, Fries can be subdivided into six main dialects: Kleifries, Woudfries, Zuidwesthoeks, Hindeloopers, Aalsters and Schiermonnikoogs. The first two mentioned Kleifries and Woudfries form the two most prevalent dialects in general use. \citep{streektalen} Kleifries and Woudfries differ in pronunciation but are increasingly similar in vocabulary. An example of this is be the word for 'you', which is 'd\^{u} in Woudfries and 'do' in Kleifries. Or the word for 'thumb', which is 't\^{u}me' in Woudfries and 'tomme' in Kleifries.   It is worth mentioning that Aalsters and Schiermonnikoogs, the Frisian dialects of the islands 'Ter schelling' and 'Schiermonnikoog' have both an endangered status of 50-150 speakers left. \citep{streektalen} \\

A research in 2004 concluded that around 440.000 people in Friesland speak Fries, with around 350.000 native speakers \citep{lewis}. A type of barbarism exists for Fries, which in Dutch is appointed with the term 'frisisme'. A 'frisisme' happens when a word or syntactical structure is formed like it would be in Fries, in another language. An example of this would be the sentence: 'Ik lig op dit stuit in bad'. In proper Dutch, this sentence would be: 'Op dit moment lig ik in bad' and in proper Fries: 'Op dit stuit lig ik yn bad'. In this example, the 'frisisme' happens because the Fries word 'stuit' is mixed with a more Dutch syntactical structure. \\

In this paper, the main question that is trying to be answered is: \emph{'is it possible to create a high quality corpus of a dialect and minority language on Twitter and to then use this corpus to identify tweets in Gronings and Frisian from Dutch tweets with high accuracy?'} This main question is attempted to be answered by the following sub questions: 
\begin{enumerate}

\item To which extent is it possible to create a high-quality corpus from Tweets that contain the Gronings dialect using seeding terms and geolocation?
\item To which extent is it possible to create a high-quality corpus from Tweets that contain the Frisian language using seeding terms and geolocation?
\item To which extent is it possible with the created corpora to correctly identify Tweets in the Gronings dialect or Frisian language?

\end{enumerate}

\chapter{Background}

\section{Language Identification}

Previous works of research have shown the usefulness of the n-gram approach, where in text subsequent features are split in vectors of n items \citep{scott}. The n-gram approach is especially useful for categorization problems since this approach works the same regardless what language is being used \citep{silva}. Errors seem to be limited to the smaller, fragmented parts of the sentence, which is helpful for classifying language on platforms on the internet, where speech might not be standardized all the time \citep{silva}.

A problem that the n-gram approach has however, is that the n-gram database can grow to excessively big proportions with a large training set, which is why often an alternative approach is chosen, such as the 'bag of words' approach, where texts are tokenized into vectors \citep{scott}.

\citep{joachims} and \citep{silva} have shown the usefulness of 'support vector machine' ('support vector clustering' or SVC) and the 'naive Bayes' algorithms to execute the task of assigning language labels to the text. \citep{joachims} found support vector machines to be currently the best performing methods for learning with text data and automatic parameter tuning through grid-search. 


\section{Dialect Identification}

Since not only the Frisian and the Dutch languages will be identified but also the Gronings dialect, this research will also include the field of dialect identification.  Dialect identification is the process of automatically determining if text contains content from a dialect and is very similar to the task of language identification. Dialect identification is harder because of the aspect that the classification happen between a group of most often close languages, rather than separate languages \citep{zaidan}. Since dialects and corresponding languages often share the same script, large parts of their vocabulary syntactical structure, they are harder to classify correctly \citep{zaidan}.

Many research has been done in the last few years on identification of languages, but less research has been done on dialect identification. Most research regarding dialect recognition has been done on Arabic dialects\citep{arabic1} \citep{arabic2}. These works of research focus on creating a multi-dialectal corpus of Arabic through the use of geographical areas on Twitter, which seemed to be highly successful. A difference with Arabic dialects however is that they differ so much from each other sometimes that they might not even be seen as dialects anymore. An example of this is the difference between the 'Maghreb' dialect, spoken in Morocco, and the 'Gulf' dialect, spoken in the UAE \citep{arabic1}. \\
Another paper has researched identification of German dialects, but puts its attention towards the spoken word \citep{ciobanu-etal-2018-german}, which used a SVM classifier that was trained on characters and words to classify transcripts of German dialects.  Working with transcript of dialects is also something Wieling has researched, who compared the Levenshtein distance of pronunciation between Dutch dialects \citep{8d03acecd9a548408debaebdb5c528b6}. \\
\citep{limburg} found that textual identification for a dialect that is similar to the language that it is distinguished from, is a lot harder than classification between regular languages. In this research a naive Bayes and support vector machine classifier was trained to classify Limburgish text. Training a classifier to identify a dialect such a Limburgish was found to be a challenge at first, because of the fact that there were no existing corpora to be found \citep{limburg}. 

\section{Identification of Twitter messages}

According to \citep{bergsma}, correctly classifying a language from messages from Twitter is an especially hard task because of the nature of Twitter messages; they are short, informal of nature and they can be of numerous different languages. \citep{bergsma} gathered their data using the Twitter API and geographical location, which retrieved messages originating from different languages. Languages such as Nepali, Urdu and Ukrainian were then manually annotated. The dataset was then used to train a logistic regression classification model and a partial matching algorithm. The logistic regression model achieved an accuracy score of over 90 percent\citep{bergsma}.

\citep{Tratz} focused on classifying Twitter messages of three languages using multinomial logistic regression and SVM's. The research implemented the dataset from Bergsma et al. (2012) together with their own that was comprised of Arabic, Farsi and Urdu and got similar results, nearing results of almost 100 percent. The dataset was comprised of 1100 Twitter messages. Then this same model was trained using the Zaidan and Callison-Burch (2011) dataset, with 3000 tweets from one Arabic dialect and 3000 tweets from other Arabic dialects, using SVM's. This time the algorithm scored significantly worse, with an accuracy of about 80 percent. \citep{Tratz} suggested that the worse score was due to complicated differences between Arabic dialects.

These two researches both come to the conclusion that seems prevalent in language and dialect identification research: that the identification of dialects is significantly harder than the identification of languages. For this research, this entails that perhaps more attention should be brought to parameter tuning and feature selection if accuracy scores should be too low.

% \input{background}    % if you have a separate file background.tex
\chapter{Data and Material}

\section{Collection} 
In this study, we use the free version of the Twitter API. The use of the free version, however, imposes some limitations on the data collection. First there is a maximum for querying Tweets of 180 requests per 15 minutes and Tweets can only be queried that are submitted in the last seven days. In order to build an initial collection of tweets that generally contain texts of the chosen (regional) languages that is substantial enough to work with, a query script was run weekly since the beginning of April. \\

To make sure that mostly Twitter messages in Gronings or Frisian are returned, this research starts by making two sets of keywords. These keywords are words that are prevalent in Gronings or Frisian Twitter messages, but not for neighboring other used languages in the area, such as Dutch, English or German. First, general Twitter messages are queried for the areas Groningen and Friesland. Then, 100 messages of each is manually annotated. These messages are compared with 100 Dutch Twitter messages to find high information words. These high information words are added to the set of keywords to query more Twitter messages. 

\begin{figure}[t]
  \includegraphics[width=\linewidth]{map.png}
  \caption{A map with the radius of geographical constraints for the Friesland and Groningen}
\end{figure}


The geolocation functionality only supports a radial specified area, which by itself already poses a challenge since the province of Groningen cannot be well specified within a circle. To solve this issue, a general approach was chosen, by choosing the village of 'Ten Boer' with a radius of 24km the largest parted of Groningen's inhabited locations could be reached by the algorithm. Since the shape of the province of Friesland lends itself better to a radial shape, less sacrifices in terms of reach had to be endured with the village of Grou and a radius of 30km covering most of the province. The initial process of gathering Tweets from a geolocation specified area without having established a set of keywords to query would probably be a tedious task especially for Gronings, as anecdotally,we've never come across a message on Twitter in the Gronings dialect. \\

The API will be run continuously for at least 2 months searching for messages that contain at least of the keywords, after which filtering of the acquired dataset starts. Unrelated languages are filtered using NLTK dictionaries. Datasets for each Gronings and Fries are separated through filtering documents to at least contain three keywords out of their respective keyword sets. A Dutch dataset of equal size is compiled using the API's language parameter, which has support for Dutch. The final result of this filtering process is a dataset of 1000 Twitter messages for both Gronings, Fries and Dutch.

\newpage

\section{annotation}
The goal of annotation is the make a dataset with predefined categories, so a machine learning algorithm can be trained and tested in a proper way, without making false assumptions. Without annotated data, supervised machine learning will be impossible.  \\
Tweets will be annotated as either 'NED', 'FRI' or 'GRO', for respectively Dutch, Frisian and Gronings. About 500 Gronings tweets were manually annotated by one native speaker. 100 Frisian tweets were manually annotated by one different native speaker. The reason for these different figures is that not enough Twitter messages for Gronings could be gathered in the collection phase to reliably annotate these messages automatically, which is why the manual annotation rate is higher for Gronings. Since Frisian messages seem to be ubiquitous, it was decided that the rest of the dataset was annotated automatically by filtering documents that contained at least five keywords. Since Twitter automatically assigns a language label to tweets from one of its 34 supported languages \citep{Hughes}, Dutch Twitter messages did not require manual annotation. \\
For each Fries and Gronings, the manual annotation part is done by one person. This begs the explanation of a possible annotation bias. Since only one native speaker annotated the foundation of this research, there is a possibility of inaccuracies when the annotator labels very selective documents. A classifier might for example perform unrealistically well, when for Fries mostly documents are annotated that contain specific language for Fries, which a classifier can easily identify. One annotator might select a group of documents that would not necessarily reflect a random group of documents of a particular language.

\section{Processing}
As far as preprocessing goes, little will done. Texts will be turned to lowercase and comma's will be removed to write the data to a CSV. Usernames in messages will be kept, just like hyperlinks and hashtags. 

\chapter{Methodology}


\section{Execution}
The purpose of this research is to find a method of automatically distinguishing Gronings and Fries from Dutch. if accurate enough, this method could in the future then be used to  increase the established corpus in the collection phase with minimal supervision.
To be able to automatically create a corpus of Fries or Gronings, a model needs to be trained to accurately identify Gronings and Fries documents from Dutch documents. \\
The two machine learning algorithms that are used are naive Bayes and SVC. The naive Bayes algorithm will make use of smoothing to increase accuracy. Its C-level will be kept at a default of 1, since that has proven to be most accurate in similar research \citep{limburg}. The SVC algorithm will be use of grid-search to automatically determine the best performing parameters. 50 percent of the data is used to train the models. The bag of words method will be used to represent the features in each document.


\section{Evaluation}

The test set is a subset with 50 percent of the whole dataset. The two different models will classify the documents in this training. The result of this process will be compared to the golden standard of correct labels. These labels are either manually assigned, or chosen by filtering documents that contain at least five keywords from a pre-compiled keywords set. These keyword sets are manually made with keywords that are unique to the dialect or language for that area and were shown were shown to be highly informative in tweets that were initially gathered. These keywords can be found in the appendix. 

Labels for the languages are translated to one of three integers for the machine learning algorithms are shown in figure 2:

\begin{figure}[h]
\begin{tabular}{ll}
	FRI & 0 \\
	NED & 1 \\
	GRO & 2 
\end{tabular}
	\caption{The original annotated label vs the output that the models will give}
\end{figure}


The classifier will compare its classified labels with the verified golden standard. The Naive Bayes and SVC models will make use of ten-fold cross validation. Every fold will return a table with the categories, precision scores, recall scores and the average F-measure for the three categories. After these ten tables with averages, a global average will be computed. Finally, the ten most informative features will be returned.

\chapter{Results and Discussion}

\section{Results}


\begin{figure}[h]
\begin{tabular}{llll}
	category & precision & recall & F-measure \\
	\hline
	0 & 0.944954 & 1.000000 & 0.971698 \\
	1 & 1.000000 & 0.941176 & 0.969697 \\
	2 & 0.988506 & 1.000000 & 0.994220 \\
	\hline
	0 & 0.973913 & 1.000000 & 0.986784 \\
	1 & 0.995455 & 0.977679 & 0.986486 \\
	2 & 0.993976 & 0.982143 & 0.988023 \\
	\hline
	0 & 0.994083 & 1.000000 & 0.997032 \\
	1 & 0.997050 & 0.994118 & 0.995582 \\
	2 & 0.991903 & 0.987903 & 0.989899 \\
	\hline
	0 & 0.991228 & 1.000000 & 0.995595 \\
	1 & 1.000000 & 0.995536 & 0.997763 \\
	2 & 1.000000 & 0.993976 & 0.996979 \\
	\hline
	0 & 0.991228 & 1.000000 & 0.995594 \\
	1 & 1.000000 & 0.995536 & 0.997763 \\
	2 & 1.000000 & 0.993976 & 0.99698 \\
	\hline
	0 & 0.984720 & 1.000000 & 0.992301 \\
	1 & 0.994575 & 0.992780 & 0.993677 \\
	2 & 1.000000 & 0.980296 & 0.990050 \\
	\hline
	0 & 0.984642 & 1.000000 & 0.992261 \\
	1 & 1.000000 & 0.989267 & 0.994605 \\
	2 & 0.997506 & 0.990099 & 0.992789 \\
	\hline
	0 & 0.976793 & 1.000000 & 0.988260 \\
	1 & 0.995475 & 0.982143 & 0.988764 \\
	2 & 0.993671 & 0.978193 & 0.985871 \\
	\hline
	0 & 0.976793 & 1.000000 & 0.988260 \\
	1 & 0.995475 & 0.982143 & 0.988764 \\
	2 & 0.993671 & 0.978193 & 0.985871 \\
	\hline
	0 & 0.988732 & 1.000000 & 0.994334 \\
	1 & 1.000000 & 0.994100 & 0.997041 \\
	2 & 1.000000 & 0.991453 & 0.995708 \\
	\hline
	0 & 0.991701 & 1.000000 & 0.995833 \\
	1 & 1.000000 & 1.000000 & 1.000000 \\
	2 & 1.000000 & 0.987421 & 0.993671 \\
	\hline




\end{tabular}
	\caption{The results returned for the ten Naive Bayes folds}
\end{figure}

\newpage

\begin{figure}[t]
\begin{tabular}{llll}
	category & precision & recall & F-measure \\
	\hline
	 0 & 1.000000  & 1.000000  & 1.000000  \\
	 1 & 0.973214  &1.000000  & 0.9864253 \\
	 2 & 1.000000  & 0.963855  & 0.981595 \\
	\hline
	 0 & 1.000000  & 1.000000  & 1.000000 \\
	 1 & 0.973214  & 1.000000  & 0.986425 \\
	 2 & 1.000000  & 0.963855  & 0.981595 \\
	\hline
	 0 & 1.000000 & 1.000000 & 1.000000 \\
	 1 & 0.993827 & 1.000000 & 0.996904 \\
	 2 & 1.000000 & 0.991935 & 0.995951 \\
	\hline
	0 & 0.997797 & 0.995604 & 0.996699 \\
	1 & 0.980044 & 1.000000 & 0.989921 \\
	2 & 0.996942 & 0.973134 & 0.984894 \\
	\hline
	0 & 0.996448 & 1.000000 & 0.998220 \\
	1 & 0.989399 & 1.000000 & 0.994671 \\
	2 & 1.000000 & 0.980907 & 0.990361 \\
	\hline
	0 & 0.998195 & 1.000000 & 0.999101 \\
	1 & 0.989726 & 1.000000 & 0.994836 \\
	2 & 1.000000 & 0.982885 & 0.991369 \\
	\hline
	0 & 0.995526 & 1.000000 & 0.997758 \\
	1 & 0.997821 & 1.000000 & 0.998909 \\
	2 & 1.000000 & 0.990881 & 0.995420 \\
	\hline
	0 & 0.996997 & 1.000000 & 0.998496 \\
	1 & 0.994269 & 1.000000 & 0.997126 \\
	2 & 1.000000 & 0.987755 & 0.993840 \\
	\hline
	0 & 1.000000 & 0.986607 & 0.993258 \\
	1 & 0.983193 & 1.000000 & 0.991525 \\
	2 & 1.000000 & 0.993671 & 0.996825 \\
	\hline
	0 & 1.000000 & 1.000000 & 1.000000 \\
	1 & 0.991597 & 1.000000 & 0.995781 \\
	2 & 1.000000 & 0.986486 & 0.993197 \\
	\hline

\end{tabular}
\caption{The results returned for the ten SVC folds}
\end{figure}

\begin{figure}[h]
\begin{tabular}{lll }
	\# & Naive Bayes & SVC \\
	1 & 0.977272 & 0.990260 \\
	2 & 0.987012 & 0.995130 \\
	3 & 0.994588 & 0.997835 \\
	4 & 0.996753 & 0.991071 \\
	5 & 0.992207 & 0.994805 \\
	6 & 0.993506 & 0.995455 \\
	7 & 0.987824 & 0.997565 \\
	8 & 0.995670 & 0.996753 \\
	9 & 0.996753 & 0.993506 \\
	10 & 0.983766 & 0.996753 \\
	\hline
	average & 0.990535 & 0.994913

\end{tabular}
\caption{The ten average f-scores and the overall average}
\end{figure}

\begin{figure}[h]
\begin{tabular}{ll}
	1 & 'boer' \\
	2 & 'lang' \\
	3 & 'ze' \\
	4 & 'fan' \\
	5 & 'nl' \\
	6 & 'mei' \\
	7 & 'it' \\
	8 & 'zijn' \\
	9 & 'niet' \\
	10 & 'ook' 
\end{tabular}
\caption{The ten most informative features}
\end{figure}

\section{Discussion}
As is shown in figure 3 and figure 4, both the SVC and the Naive Bayes models performed very well. Average F-measures returned as respectively 0.995 for the SVC model and 0.991 for the Naive Bayes model as shown in figure 5. These two measures are far beyond expectations. Similar research that covered the task of language identification had similar scores (citation needed) and similar dialect identification tasks had mostly lower scores as output. \\

These high results come as a surprise, as similar approaches to comparative research that was mentioned in the background section. Naive Bayes and SVC models were used in relevant research with lower scores \citep{bergsma}. The parameter values are chosen through grid-search, which is not unusual in the field of machine learning. One reason for these high results could be that the Twitter messages for each of the three categories of Frisian, Dutch and Gronings is highly unique. Through the selection process of finding unique keywords, these messages all have unique features that could make them easier to classify. As is visible in the top ten most informative features, words such as 'ek', 'fan', 'mei' and 'it' are predominantly Frisian. Even though 'mei' also has a dutch meaning, nearly no Dutch Twitter messages made reference to this word. The word 'boer' was most often used for the classification of messages in the Gronings category.  \\
An interesting result, because this word is the same in all three categories. This means that in this dataset messages in the Gronings dialect mention the word 'boer' extensively more than either Dutch or Frisian. Dutch terms such as: 'lang', 'ze', 'nl', 'zijn', 'niet' and 'ook' were all predominantly words used to correctly classify documents as Dutch. These are all often occurring words and thus not surprising, except for the word 'nl'. In this dataset, 74 documents contain the token 'nl', which are all correctly classified as Dutch. This could either be the result of an often reoccurring abbreviation for ones own country, or a small bias in the dataset. It seems that the corpora for each Gronings and Frisian are both very unique, which makes it possible that the correct classification rate is so high.

\chapter{Conclusion}
This research attempted to investigate the possibility of creating a high quality corpus of a dialect and minority language on Twitter and to use this corpus to identify Tweets in Gronings and Frisian from Dutch Tweets with high accuracy.
In order to achieve this, First the possibility of creating high quality corpora of tweets in both Gronings and Fries with geographical constraints was looked into. This proved harder for Gronings, as usage of this dialect is far less prevalent on Twitter. With manually annotated initial Tweets, a set of keywords was used to more narrowly specify queries which resulted in more Gronings Tweets, which could then be used to further increase a keyword set.\\
Frisian proved to be easier at gathering data. Even without keywords high quality Frisian messages were already in excess. Still, a list of keywords that was reported as most informative was made. \\

Both corpora were confined to a maximum of 1000 documents. On half of these corpora, a naive Bayes and SVC model was trained. These models are then tested on the other half of the corpora, using ten-fold cross-validation. The results of these models turned out to be very high, reporting F-measures of 99.1 and 99.5 percent for naive Bayes and SVC respectively. \\

The resulted corpora for Gronings and Fries seem to be of quite high quality textual-wise. Most language in these corpora is not Dutch as documents have a minimum of five Gronings / Frisian words. The models trained on these corpora show very high scores, showing that it is possible to create high-quality corpora from Twitter messages and to use those corpora to identify messages that contain Fries and Gronings.
A limitation of this work is that the exceedingly high score could be helped by annotator bias, since only one annotator for each Gronings and Fries participated. 
%----------------------------------------------------------------------------------------
%	BIBLIOGRAPHY
%----------------------------------------------------------------------------------------

\bibliographystyle{aclnatbib} 
\bibliography{thesis-IK}



\end{document}

